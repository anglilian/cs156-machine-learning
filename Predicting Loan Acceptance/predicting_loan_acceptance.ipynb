{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS156 Assignment 2\n",
    "## Ang Li-Lian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Variables\n",
    "For the rejected dataset, I included the amount requested, debt-to-income ratio and employment length. The others were removed because they were irrelevant to whether they would receive the loan (applicant location, date) or were inconsistent and incomparable with the accepted dateset (risk score with both FICO and Vangard Score).\n",
    "\n",
    "For the accepted dataset, the loan amount, employment length and debt-to-income ratio were chosen because they provide a point of comparison with the rejected dataset. As for the other columns of data,all entries regarding settlement, joint applications, deferrals and hardship plans were removed since they only represent a small subset of the data. They are exceptions to the rule which we won't take into account when making a generalisable model.\n",
    "\n",
    "In terms of ethical issues, I did not include any data regarding location since the dataset comes from the US where there is a history of housing segregation in certain states. These would have negatively impacted previous data of whether a person was or wasn't accepted for a loan based on their race (which is not a category here, but could be correlated with location). Besides, the person's address intuitively also doesn't affect their ability to pay for a loan and would only obscure other more relevant relationships.\n",
    "\n",
    "The other columns were chosen based on what would indicate that a person can be trusted to pay back a loan. These include having a good track record of paying on time, having enough money to afford the loan and having a long enough track record. To this end, there are several columns of redundant that are highly correlated and give essentially the same information. For example: \"delinq_2yrs\" gives the number of 30+ days past-due incidences and \"pct_tl_nvr_dlq\" gives the percent of trades never delinquent. These two are inversely correlated thereby diluting the effect of variable during analysis especially if many similar ones included. Loan grades are also not included because it already takes into account all of these variables to output a score. Here, we are trying to estimate the risk similar to what these scores would tell us.\n",
    "\n",
    "### Good track record\n",
    "- \"num_accts_ever_120_pd\": number of accounts ever past 120 or more days past due\n",
    "- \"total_rec_late_fee\": Late fees received to date\n",
    "- \"pct_tl_nvr_dlq\": percentage of trades never delinquent\n",
    "- \"last_fico_range_high\": upper boundary of FICO\n",
    "\n",
    "### Long track record\n",
    "- \"earliest_cr_line\" - Earliest reported credit line opened\n",
    "- \"mo_sin_old_il_acct\" - Months since oldest bank installment account opened\n",
    "- \"mo_sin_old_rev_tl_op\" - Months since oldest revolving account opened \n",
    "\n",
    "### Sufficient and stable funds\n",
    "- \"dti\": ratio of monthly debt payments to monthly income\n",
    "- \"bc_util\": ratio of current balance to credit limit for all bankcard accounts\n",
    "- \"il_util\": ratio of total current balance to credit limit on all install accounts\n",
    "- \"inq_fi\": number of personal finance inquiries\n",
    "- \"emp_length\": employment length\n",
    "- \"home_ownership\": home ownership status\n",
    "- \"verification_status\": Income verified by LC\n",
    "- \"purpose\": reason for loan request\n",
    "\n",
    "## Dealing with NA's\n",
    "If there was less than 5% of NAs, all rows with NAs were dropped. The rationale is that this constitutes a very small subset of the data (especially since our dataset is huge), so dropping the data will not affect our sample size. Imputing these entries instead would reduce the variance of our results, giving us more confidence than we should have in our results. To prevent this, we remove the small amount of data.\n",
    "\n",
    "However, if there was 5% or more NAs, the missing values would be imputed with the mean because removing the data would mean having a significantly smaller data set. Here, we assume that our data is missing at random (rather than having a specific pattern). Therefore, replacing the missing values with the mean would be a good substitute.\n",
    "\n",
    "## Categorical Data\n",
    "All categorical data was converted into numerical data using One Hot Encoding that removed the implicit hierarchy simply changing them into ordinal categories would. For Employment Length, categories for \"> 10 Years\" and \"<1 Year\" was converted into 10 and 0 respectively and the whole column was converted into integers. This is because there is a hierarchy involved.\n",
    "\n",
    "## Datetime Data\n",
    "All datetime data was converted into datetime objects and then into floats so they match with the data type of all other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Data source: https://www.kaggle.com/datasets/wordsforthewise/lending-club\n",
    "accepted = pd.read_csv(\"accepted_2007_to_2018Q4.csv.gz\", nrows= 10000)\n",
    "accepted = accepted[[ \n",
    " 'dti',\n",
    " 'emp_length',\n",
    " 'funded_amnt',\n",
    " 'home_ownership',\n",
    " 'num_accts_ever_120_pd',\n",
    " 'pct_tl_nvr_dlq',\n",
    " \"purpose\",\n",
    " 'bc_util',\n",
    " 'earliest_cr_line',\n",
    " 'il_util',\n",
    " 'inq_fi',\n",
    " 'last_fico_range_high',\n",
    " 'mo_sin_old_il_acct',\n",
    " 'mo_sin_old_rev_tl_op',\n",
    " 'total_rec_late_fee',\n",
    " 'verification_status']]\n",
    "\n",
    "# Transforming Ordinal Data into numeric\n",
    "accepted[accepted[\"emp_length\"]==\"< 1 year\"]  =\"0\"\n",
    "accepted['emp_length'] = accepted['emp_length'].str.extract('(\\d+)', expand=False)\n",
    "accepted['emp_length'] = accepted['emp_length'].astype(float)\n",
    "\n",
    "# Removing Missing Data\n",
    "percent_missing = accepted.isnull().sum() * 100 / len(accepted)\n",
    "\n",
    "# Very small NAs\n",
    "drop = percent_missing.index[(percent_missing.values>0)&(percent_missing.values<=5)].tolist()\n",
    "accepted = accepted.dropna(subset = drop)\n",
    "\n",
    "# Too significant NAs to drop\n",
    "fill = percent_missing.index[(percent_missing.values>5)].tolist()\n",
    "for x in fill:\n",
    "    accepted[x]=accepted[x].astype(float)\n",
    "    accepted[x]= accepted[x].fillna(accepted[x].mean())\n",
    "\n",
    "# Transform categorical value into numeric\n",
    "for col in [\"home_ownership\", \"verification_status\", \"purpose\"]:\n",
    "    encode = OneHotEncoder().fit_transform(np.array(accepted[col]).reshape(-1,1)).toarray()\n",
    "    encode=encode.astype(int)\n",
    "    accepted[col] = [''.join(map(str, l)) for l in encode]\n",
    "    accepted[col]=accepted[col].astype(float)\n",
    "\n",
    "# Transform datetime objects to numeric\n",
    "for col in  [\"earliest_cr_line\"]:\n",
    "    accepted[col]=pd.to_datetime(accepted[col], infer_datetime_format=True, errors= \"coerce\")\n",
    "    accepted[col]=accepted[col].values.astype(int)\n",
    "\n",
    "# Convert all columns to float type\n",
    "accepted= accepted.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source https://www.kaggle.com/datasets/wordsforthewise/lending-club\n",
    "rejected = pd.read_csv(\"rejected_2007_to_2018Q4.csv.gz\", nrows= 10000)\n",
    "rejected = rejected[[\"Amount Requested\", \"Employment Length\", \"Debt-To-Income Ratio\"]]\n",
    "\n",
    "# Rename columns to same name as accepted\n",
    "rejected = rejected.rename(columns ={\"Amount Requested\":\"funded_amnt\", \n",
    "    \"Employment Length\":\"emp_length\", \"Debt-To-Income Ratio\":\"dti\"})\n",
    "\n",
    "# Transform categorical value into numeric\n",
    "rejected[rejected[\"emp_length\"]==\"< 1 year\"]  =\"0\"\n",
    "rejected['emp_length'] = rejected['emp_length'].str.extract('(\\d+)', expand=False)\n",
    "rejected['emp_length'] = rejected['emp_length'].astype(int)\n",
    "\n",
    "# Removing Missing Data\n",
    "percent_missing = rejected.isnull().sum() * 100 / len(rejected)\n",
    "\n",
    "# Very small NAs\n",
    "drop=percent_missing.index[(percent_missing.values>0)&(percent_missing.values<=10)].tolist()\n",
    "rejected = rejected.dropna(subset = drop)\n",
    "\n",
    "# Too significant NAs to drop\n",
    "fill = percent_missing.index[(percent_missing.values>10)].tolist()\n",
    "rejected[fill]= rejected[fill].fillna(rejected[fill].mean())\n",
    "\n",
    "# Convert str to float\n",
    "rejected['dti'] = rejected['dti'].str.rstrip('%').astype('float')\n",
    "\n",
    "# Convert all columns to float type\n",
    "rejected=rejected.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and label dataframes\n",
    "df = pd.concat([rejected,accepted])\n",
    "df[\"label\"]= [0]*len(rejected)+ [1]*len(accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "## Split into train and test sets\n",
    "The data was randomly split into training and test sets. Note that both data sets also have about the same sample size with the accepted data set being slightly lower because some rows of data were removed, but this is a negligible percentage difference. To prevent leakage of data, the test set was not used at all in any scaling or model preparations. It was only used to find the score of the model. The variable to be predicted was separated out. In the first case it was the funding amount for predicting how much loan a person would receive. The second case is to predict if a person would be accepted or rejected from a loan.\n",
    "\n",
    "## Scaling Data\n",
    "A scaler was trained on the training data set and used to transform the training and test data set. To prevent data leakage, the test set was not included to scale the data. \n",
    "\n",
    "The data was scaled to normalise and center values which were originally on very different magnitudes. This will ensure that all features contribute proportionally to the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accepting or Rejecting a Loan\n",
    "\n",
    "I've built the following K-Nearest Neigbours model to evaluate whether someone will be accepted or rejected from a loan. Since there are only three overlapping columns between the accepted and rejected database, the number of features is quite small. I tweaked the parameter for class weight so that it adjusts the weights of the data according to the frequency of classes and this gave a marginally better score.\n",
    "\n",
    "Banks are usually very risk averse because they have a lot at stake to lose if someone is unable to pay back their loan. Therefore, we want our model to minimise the number of false positives (people who should be rejected from a loan, but were accepted) and maximise true positives (accepting people who should be accepted). This means we want a high precision score.\n",
    "\n",
    "To prevent any leakage in data, we will perform a cross-validation using just the training set and determine which value of K should be used for the K-nearest neighbours to give the highest precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69      2480\n",
      "           1       0.68      0.72      0.70      2442\n",
      "\n",
      "    accuracy                           0.70      4922\n",
      "   macro avg       0.70      0.70      0.70      4922\n",
      "weighted avg       0.70      0.70      0.70      4922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,average_precision_score\n",
    "\n",
    "# Split into training and test data with loan amount as objective\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"emp_length\",\"dti\"]], df[\"label\"])\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# search for an optimal value of K for KNN\n",
    "k_range = range(1, 10)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_validate(knn, X_train, y_train, cv=10, scoring=['precision_macro'])\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores[\"test_precision_macro\"].mean())\n",
    "\n",
    "K = k_scores.index(max(k_scores))+1 # K with highest precision\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=K)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final precision score is higher for class 0 (rejected) than class 1 (accepted) which shows that the model is doing what we intended which is to maximise the detection of those who should truly be rejected from getting a loan. The scores in general across the board are also fairly high which shows that the model is performing well in predicting who should be given a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Largest Loan Amount to be Successfully Funded \n",
    "\n",
    "Now that we know which applicants have been accepted, we can predict how much loan they will receive. Let's suppose that after screening the applicants, we have a list of all applicants who have been accepted for the loan. In this case, some of our predicted loan applicants might be from the rejected dataset so they won't have any data for other features. For the purposes of this model, let's use the original accepted dataset as a proxy.\n",
    "\n",
    "We will split the training and test dataset as before, but with the loan amount as our objective. We are also scaling the X_train data to centre and standardise the variance so that all components are given equal consideration. To prevent any data leakage, we will not use X_test until we perform the final test. \n",
    "\n",
    "Compared to choosing a regular linear regression, a ridge regression will reduce overfitting in the data by introducing a small amount of bias to improve the performance of the model on unseen data. The alpha value changes how flexible the fit of the curve is. To determine what would be the appropriate alpha value to use we will conduct cross validation on the alpha value for the Ridge regression and select the number of components based on the highest R-squared. Note that we are performing 10-fold cross validation only on the training set, so the test set data will be unseen until the very end, preventing data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "# Split data into training and test set\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "        accepted.drop([\"funded_amnt\"],axis =1),accepted[\"funded_amnt\"])\n",
    "\n",
    "cols = X_train.columns # feature names\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# search for an optimal value of K for KNN\n",
    "k_scores = []\n",
    "\n",
    "for k in np.arange(0.1,1,0.1):\n",
    "    reg =  Ridge(alpha=k)\n",
    "    scores = cross_validate(reg, X_train, y_train, cv=10, scoring=[\"r2\"])\n",
    "    k_scores.append(scores[\"test_r2\"].mean())\n",
    "\n",
    "K = k_scores.index(max(k_scores))+1 # K with highest R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum predicted loan amount: $23462.37\n",
      "Root Mean Squared Error: 7929.00\n",
      "Ratio of Mean to RMSE: 0.57\n",
      "R-Squared: 0.2847238001536029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>-3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>33.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>21.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <td>-52.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <td>128.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util</th>\n",
       "      <td>21.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il_util</th>\n",
       "      <td>-22.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_fi</th>\n",
       "      <td>130.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <td>51.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>-15.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Coefficient\n",
       "dti                          -3.78\n",
       "emp_length                   33.87\n",
       "home_ownership               21.10\n",
       "num_accts_ever_120_pd       -52.09\n",
       "pct_tl_nvr_dlq              128.76\n",
       "purpose                      -0.00\n",
       "bc_util                      21.23\n",
       "earliest_cr_line              0.00\n",
       "il_util                     -22.54\n",
       "inq_fi                      130.28\n",
       "last_fico_range_high          5.26\n",
       "mo_sin_old_il_acct           13.45\n",
       "mo_sin_old_rev_tl_op         13.59\n",
       "total_rec_late_fee           51.69\n",
       "verification_status         -15.26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = Ridge(alpha=K).fit(X_train, y_train) # fit model according to optimised alpha\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "test_set_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_set_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Maximum predicted loan amount: ${'{:.2f}'.format(max(y_pred))}\")\n",
    "print('Root Mean Squared Error:', '{:.2f}'.format(test_set_rmse))\n",
    "print('Ratio of Mean to RMSE:', '{:.2f}'.format(test_set_rmse/np.mean(y_test)))\n",
    "print(f\"R-Squared: {test_set_r2}\")\n",
    "coeff_df = pd.DataFrame(reg.coef_, cols, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown here, we have a predicted maximum loan amount with an R-squared value of about 0.3 which is a fairly low number. This means that the model represents almost 30% of the data which can be considered quite good given the size of our data. To understand how relatively low or high the RMSE is, we will compute its ratio compared to the mean of the actual data. The error is more than 50% of the mean which shows quite a bit of variance. However, since the model was built with careful consideration to not have any leakage from the test set and used a high number of samples to begin with, this model will be generalisable to unseen data.\n",
    "\n",
    "The coefficients of the Ridge regression also tells us how well each variable describes the model. In this case, 'purpose' and \"earliest_cr_line\" play next to no role, so they could be removed without any loss to the model itself. But I have left them in the model because when selecting variables, they were intuitvely important to determining loan amount and and approval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
